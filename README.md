## Paula Lindgren - Self Assessment

-   Self Assessment
    -   I would say I took more of a leadership role
    -   We were all pretty introverted so that was a little difficult at first, especially as strangers
    -   I helped guide us to the datasets we were going to use do to limited time for the project. It had to be simple and doable in the few weeks we had.
    -   I added some SQL code to Corey's original code.
    -   I ran the inital models and EDA code. The code was shared with the whole team for comment and edits
    -   I helped edit the HTML code created by Corey and Quinn.
    -   I created the Tableau dashboard.
-   Team assessment
    -   The people on the team were very friendly and respectful of each other. We are connected on LinkedIn now and I hope for future connections to see how people are progressing in their careers after this bootcamp.
    - It was difficult when one person dropped out without any notice but it was understandable with their personal issues. I think people really need to have completed most of the Challenges. It was hard with someone who was really far behind in the course work.
    -   I honestly was dreading the final project for most of the class since it was a group project. As  much as I wanted to do an individual project, I had a great experience with the group.
-   Summary of the Project
    - This goal of this project was to compare the performance of supervised machine learning models. Red and white wine ratings data sets were obtained from kaggle.com. Each data set had eleven physiochemical measurements in wine and quality ratings are the outcome. The quality ratings (0-10) were recoded into a binary outcome Good vs Not good wine. Good was defined as >= 7 and Not good was <7. The data were scaled using the Standard Scaler with mean=0 and standard deviation=1. Scaling the data makes the models comparable. Two over sampling and one under sampling techniques were used to address imbalanced sample. A train and test data set was created to use in each model. Models were evalated by accuracy, precision, recall and F1 score.
    -   Here are the models evaluated:
        - Logistic
        - Support Vector Machines
        - Decision Tree
        - Random Forest
        - Gradient Boosted Tree
        - Logistic-Random Oversampling
        - Logistic-Synthetic Minority Over-sampling Technique
        - Logistic-Cluster Centroid Undersampling
        - Balanced Random Forest Classifier
        - Easy Ensemble Ada Boost Classifier
    - Results
        - The Random Forest and Balanced Randon Forest models had the best perfomance for red and white wine data.

